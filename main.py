import av
import os
import sys
import streamlit as st
from streamlit_webrtc import VideoHTMLAttributes, webrtc_streamer
from aiortc.contrib.media import MediaRecorder # Necesario si MediaRecorder se usa internamente

# Ajustar el sys.path si los archivos utils.py, process_frame.py y thresholds.py
# no est치n en el mismo directorio principal. Si los copiaste al mismo directorio,
# estas l칤neas no son estrictamente necesarias pero no causan da침o.
BASE_DIR = os.path.abspath(os.path.join(__file__, '../../'))
sys.path.append(BASE_DIR)

# Importar las funciones y clases necesarias de tus archivos auxiliares
from utils import get_mediapipe_pose
from process_frame import ProcessFrame
from thresholds import get_thresholds_beginner # Usaremos los umbrales de principiante para un ejemplo

# --- Modificaciones de texto y eliminaci칩n de opciones de modo ---
st.title('Detector de Poses Simple con IA') # T칤tulo principal en espa침ol
st.write('Con esta aplicaci칩n, puedes configurar f치cilmente detecciones de poses a partir de tu webcam para diversas aplicaciones, como juegos de baile o an치lisis de movimientos.') # Texto introductorio en espa침ol

# --- Inicializaci칩n de los componentes de procesamiento de poses (parte de la app original de sentadillas) ---
# Usaremos los umbrales de principiante para el demo.
# La app de sentadillas ya define 'thresholds' en su l칩gica.
thresholds = get_thresholds_beginner() 

# Inicializar la clase de procesamiento de fotogramas.
# Esta clase contiene la l칩gica para procesar los fotogramas y dibujar sobre ellos.
live_process_frame = ProcessFrame(thresholds=thresholds, flip_frame=True)

# Inicializar el objeto de pose de MediaPipe.
# Esta funci칩n viene de tu archivo utils.py.
pose = get_mediapipe_pose()

# --- Callback de fotogramas de v칤deo (como en tu 1_游닝勇_Live_Stream.py) ---
def video_frame_callback(frame: av.VideoFrame):
    # Convertir el fotograma AV a un array NumPy en formato RGB24
    frame_rgb = frame.to_ndarray(format="rgb24")
    
    # Procesar el fotograma usando tu l칩gica de ProcessFrame (an치lisis de sentadillas)
    # y el objeto de pose. La funci칩n .process() devuelve el fotograma anotado y una se침al de sonido.
    annotated_frame_rgb, _ = live_process_frame.process(frame_rgb, pose)
    
    # Convertir el array NumPy anotado de nuevo a un av.VideoFrame en formato RGB24
    return av.VideoFrame.from_ndarray(annotated_frame_rgb, format="rgb24")

# --- Configuraci칩n de Streamlit WebRTC (como en tu 1_游닝勇_Live_Stream.py) ---
ctx = webrtc_streamer(
                        key="simple-pose-detector", # Una clave 칰nica para el streamer
                        video_frame_callback=video_frame_callback, # Tu funci칩n de procesamiento de fotogramas
                        rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]}, # Configuraci칩n est치ndar de WebRTC
                        media_stream_constraints={"video": {"width": {'min':480, 'ideal':480}}, "audio": False}, # Restricciones de medios (solo v칤deo)
                        video_html_attrs=VideoHTMLAttributes(autoPlay=True, controls=False, muted=True), # Atributos HTML del v칤deo (sin controles, silenciado)
                        # Eliminado out_recorder_factory y l칩gica de descarga para simplificar
                    )

# --- Texto final en la interfaz ---
st.write("Esta demostraci칩n muestra c칩mo es posible realizar un detector de poses en vivo usando tu c치mara.") # Nuevo texto final